# 8/9
- モデル作成時にパラメータは最初から値が設定済みとなっている
- 各パラメータの分布は標準一様分布から生成される
- 2つのθの中間値を求める処理の実装中

# 8/10
- ファイル毎に処理を分割してテスト中
- 細かい修正はまだまだ多い
- GoogleColabo上にフォルダ毎アップロードして検証しよう
- 修正はローカルのPycharmで、実行はクラウドにて

# 8/11
- 1次元版は動いたので2次元版の実装中
- BNの処理の実装は後で行う
- net_plotter.pyの実装が参考になる
- 2次元版になると別の課題が発生することがわかった
- というかこちらの課題掘り進めるといくらでも根が深いところまですすんでしまう
- https://arxiv.org/abs/1712.09913
- とりあえず2次元版の実装をまず考えよう
- これ自体は対して難しくない
- ライブラリの依存関係なんやらで結局移植。Pytorchのライブラリの勉強に丁度よいということにしよう

# 8/12
- GoogleColab上のGPUありで1分で3点計算可能。2000点なら10時間以上かかってしまう
- 思っていたよりも全然時間がかかる。単純な数値計算なので並列化が一番効くはずなのだがColabだとうまく動作しない
- AlexNetの超曲面を3次元上に再現できた。もともと原点を学習済みのロスの最小値にするのが正解だが、そこは忘れてしまった
- モデルのパラメータのテンソルがGPUとCPUで互換性がない。計算直前まではモデルはCPUで扱い計算時にGPUに変更している

# 8/13
- 学習済みモデルからAlexNetを3次元上への再現が完了した
- 実装の大枠は完成したので後は細かい修正を行う
- 本来はtrain_dataの代わりにtest_dataを用いて可視化するのが望ましい[要修正]
- .pyファイルと.mdファイルが混在しているので新規にsrcディレクトリを作るべき
- cuda環境で保存したmodelはcpu環境では開けない[要修正]

# 8/15
- リファクタリング中
- 元のソースコードがスクリプト言語を無理にPythonに変換したような書き方。読んでもあまり勉強にならない
- 全般的に疎結合になっていない。特に非同期処理
- できれば綺麗に書き直したいが時間がない...
- cuda環境のみで実行できるのが望ましい[要修正]
- dir-typeとignoreに関しては再度論文をチェックする必要がある
- 明日はAWSのGPU環境で検証する

# 8/16
- 座標周りは無駄な処理を行っている気が...
- AWSのGPUインスタンス上で実行するとすごく早くてびっくり
- Cifar10用のVGGやResNetのモデルのコードが残っているのが助かる